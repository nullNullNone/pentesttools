from xml.dom.minidom import parse

def fxmlli(file,cuts,elems = []):
    li = []
    obj = parse(file).documentElement
    for x in obj.getElementsByTagName(cuts):
        di = {}
        for xx in elems:
            temp = []
            for xxx in x.getElementsByTagName(xx):
                temp.append(xxx.firstChild.data)
            di[xx]= temp
        li.append(di)
    return li
###############################################################################################################################################################################
class FError(Exception):
    pass
################################################################################################################################################################################
import requests
# from fake_useragent import UserAgent
import time
import random
import traceback
import sys
import requests_html

requests.packages.urllib3.disable_warnings()
from requests import sessions
# import ssl
# ssl._create_default_https_context = ssl._create_unverified_context
class http_proc():
    sel = ''
    defua = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36 Edge/15.15063"
    def http_coon(self,
                  host, ua=defua, pa='',data='',
                  timeoutd=5,gap = 0,
                  vis = True,retry = '',skip=False,
                  stashow = False,rais_e = '',
                  connect_num=5,js = False,
                  method="get",heads1={}):
                net_sta = True
                host = host.strip()
                while net_sta:
                    try:
                        time.sleep(gap)
                        heads = {'User-Agent': ua}
                        if(len(heads1)>0):
                            heads.update(heads1)
                        requests.adapters.DEFAULT_RETRIES = connect_num

                        if js:
                            res = self.get2(url=host,headers=heads,timeout=timeoutd)
                        else:
                            if method=="get":
                                res = requests.get(url=host, headers=heads, params=pa, timeout=timeoutd, verify=False)
                            elif method == "post":
                                res = requests.post(url=host, headers=heads, params=pa, timeout=timeoutd, data=data,verify=False)



                        statucode = res.status_code
                        if vis and statucode <= 200:
                            print(str(statucode)+' '+'->')
                        elif vis and statucode >= 200:
                            print(str(statucode)+' '+'-x')
                        else:
                            pass
                        # 500 500 200 500


                        if 'reflect,' in retry:
                            if str(statucode) not in retry:
                                net_sta = True
                            else:
                                net_sta = False
                        elif str(statucode) not in retry:
                            net_sta = False
                                # print(str(statucode))
                        if stashow:
                            print("porc-stat:"+str(net_sta))



                    except:
                        print("here errors"+"expect:"+str(net_sta))
                        if skip:
                            net_sta=False
                        if len(rais_e)>0:
                            traceback.print_exc()
                            sys.exc_info()
                            raise FError(rais_e)
                        else:
                            traceback.print_exc()
                            sys.exc_info()
                        print("here errors" + "expect:" + str(net_sta))
                        pass


                return res

    def rand_ua(self,my_ua = [
        "Mozilla/5.0 (Windows Phone 8.1; ARM; Trident/7.0; Touch; WebView/2.0; rv:ddd1.0; IEMobile/ddd1.0; NOKIA; Lumia 525) like Gecko",
        # UserAgent().ie,
        "Mozilla/5.0 (Linux; Android ddd1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.120 Mobile Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36 Edge/15.15063",
    ]):
        return my_ua[random.randrange(len(my_ua))]


    def rand_ua_json(self,my_ua = [
        "Mozilla/5.0 (Windows Phone 8.1; ARM; Trident/7.0; Touch; WebView/2.0; rv:ddd1.0; IEMobile/ddd1.0; NOKIA; Lumia 525) like Gecko",
        # UserAgent().ie,
        "Mozilla/5.0 (Linux; Android ddd1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.120 Mobile Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36 Edge/15.15063",
    ]):
        return {"User-Agent":my_ua[random.randrange(len(my_ua))]}

    def get2(self,url,timeout,headers):
        ss = requests_html.HTMLSession()
        r = ss.get(url,timeout=timeout, headers=headers)
        r.html.render()
        return r

    def get_text(self,url="", code="utf8", sleep=0.2,pa='',data='',method="get",heads={},timeoutd=30,retry='reflect,200'):
        res = self.http_coon(host=url,retry=retry,
                             pa=pa,vis=True,gap=sleep,
                             timeoutd=timeoutd,method=method,
                             ua=self.rand_ua(),heads1=heads,data=data
                             )
        res.encoding = code
        text = res.text
        return text


    def get_text_save(self,path="",url="", code="utf8", sleep=0.2,pa='',method="get",heads={}):
        res = self.http_coon(host=url, retry='reflect,200',
                             pa=pa, vis=True, gap=sleep,
                             timeoutd=30, method=method,
                             ua=self.rand_ua(), heads1=heads
                             )
        res.encoding = code
        text = res.text
        try:
            f = open(path,"a",encoding=code)
            f.write(text)
            f.close()
        except Exception as e:
            print(FError("can not dump html"))
            return None
        return text

    def upload(self):
        pass
#
# l = http_proc()
# res = l.http_coon(host="https://www.wwwwwwwwwwwwwwwwwwwwwu.com",retry='reflect,200',vis=True).text
# print(res)
# l.selen_get("https://www.baidu.com")
################################################################################################################################################################################
#########################################################################################################################################################
from lxml import etree

def solve_one(obj,rules):
    src = etree.HTML(obj)
    res = []
    try:
        res = src.xpath(rules)
    except:
        pass
    return res

def rr_pick(obj,res = {}):
    for x in obj:
        if "lxml.etree._Element" in str(type(x)):
            rr_pick(x)
        if res.get(obj2tag(x),None) == None:
            res[obj2tag(x)] = [[],[]]
        res[obj2tag(x)][0].append(objattr(x))
        res[obj2tag(x)][1].append(getone(x, "./*//text()"))
    return res

def handle(http,xpath):
    res = set()
    src = etree.HTML(http)
    return src.xpath(xpath)

def getone(obj,xpath):
    return obj.xpath(xpath)

def obj_solve(obj,rules = {}):
    src = etree.HTML(obj)
    res = {}
    for x in rules:
        try:
            res[x]=src.xpath(rules[x])
        except:
            pass
    return res

def alltaga(html):
    res = set()
    src = etree.HTML(html)
    for x in src.xpath("//*"):
        if str(x).split(" ")[1] == "a":
            try:
                if len(x.xpath("./@href")) > 0:
                    if x.xpath("./@href")[0].strip().startswith("http"):
                        res.add(x.xpath("./@href")[0])
            except:
                pass
    return list(res)

def alltags(html):
    res = set()
    src = etree.HTML(html)
    return src.xpath("//*")

def obj2tag(obj):
    return str(obj).split(" ")[1]

"""
x = {_Element} <Element meta at 0x19275bf38c0>
 attrib = {_Attrib} {'http-equiv': 'Content-Type', 'content': 'text/html; charset=UTF-8'}
 base = {NoneType} None
 nsmap = {dict} <class 'dict'>: {}
 prefix = {NoneType} None
 sourceline = {int} 6
 tag = {str} 'meta'
 tail = {str} '\r\n'
 text = {NoneType} None
"""
def objattr(obj):
    # return obj.xpath('./@*')
    return obj.attrib

def xsolv_test():
    pass
    # res = http_proc().get_text(url='http://www.weather.com.cn/weather/101210101.shtml')
    # xsolv = {'1': '//li[@class="sky skyid lv3 on"][1]/h1/text()',
    #          '2': '//li[@class="sky skyid lv3 on"][1]/p[1]/text()',
    #          '3': '//li[@class="sky skyid lv3 on"][1]/p[2]/span/text()',
    #          '4': '//li[@class="sky skyid lv3 on"][1]/p[2]/i/text()',
    #          '5': '//li[@class="sky skyid lv3 on"][1]/p[3]//span[1]/@title',
    #          '6': '//li[@class="sky skyid lv3 on"][1]/p[3]//span[2]/@title',
    #          '7': '//li[@class="sky skyid lv3 on"][1]/p[3]//i/text()',
    #          '8': '//div[@class="crumbs fl"]/a/text()',
    #          '9': '//ul[@class="clearfix city"]//text()'
    #          }
    #
    # ss = obj_solve(obj=res, rules=xsolv)
    # print(ss)

def solvtest2():
    res =  http_proc().get_text(url='https://www.baidu.com/s?tn=88093251_10_hao_pg&ie=utf-8&wd=8uftp')
    print(rr_pick(handle(res,'//div[@class="result c-container new-pmd"]')[0]))
    # for x in handle(res,'//div[@class="result c-container new-pmd"]')[0]:
    #     print(type(x),x)
    # rr_pick(handle(res, '//div[@class="result c-container new-pmd"]')[0], "./a/@href")
    # rr_pick(handle(res, '//div[@class="result c-container new-pmd"]')[0], "./img/@src")
    # picklist(handle(res,'//div[@class="result c-container new-pmd"]')[0])
    # for x in handle(res,'//div[@class="result c-container new-pmd"]'):
    #     # print(obj2tag(x),objattr(x),)
    #     rr_pick(x,"//*")

# solvtest2()
##############################################################################################################################################################

def li2str(li = []):
    res = ""
    for x in li:
        res += x
    return res

def head2dict(fi):
    res = {}
    with open(fi,"r") as ff:
        for x in ff.readlines():
            key = x.split(":")[0]
            value = li2str(x.split(":")[1:])
            res[key]=value.strip()
        ff.close()
    return res
#########################################################################################################################
import csv
class Csv_tools:
    head = []
    file = ""
    Writer = None

    def open(self,file = "",op="w",code="iso-8859-1"):
        self.file = file
        self.Writer = csv.writer(open(self.file,op,encoding=code,newline=''))

    def writehead(self,head):
        self.head = head
        self.Writer.writerow(self.head)

    def writelist(self,li=[]):

        self.Writer.writerow(li)
####################################################################################################################################
import re
def re_pick_n(parm,string1):
    return re.findall(re.compile(parm),string1)
################################################################################################################
def la(l,x):
    if l == 0:
        return l
    if l < len(x)-1:
        return l
    else:
        return len(x)-1
#############################################################################################
print("""
    spyder all cves with some imfomation or exp
""")


i  = 0
con = http_proc()
# for x in js:

cc = Csv_tools()
cc.open("cves.csv",code="utf-8")
cc.writehead(["漏洞名称","漏洞链接","CVE编号","漏洞平台","发布时间","更新时间"])
text = con.get_text(retry="", url="https://www.anquanke.com/vul?page=1")
page = obj_solve(text, {"page": '//li[@class="page-item"][2]//a[@tabindex="-1"]/@href'})
page = int(li2str(re_pick_n("[0-9]",page["page"][0])))
baseurl = "https://www.anquanke.com/"

for x in range(1,page+1):
    url = "https://www.anquanke.com/vul?page={}".format(x)
    print(url)
    text = con.get_text(retry="", url=url)

    vulns = obj_solve(text,
                      {"vlink": '//div[@class="container d-flex justify-content-between vul"]//tr//td[1]//a//@href',
                       "vname": '//div[@class="container d-flex justify-content-between vul"]//tr//td[1]//a//text()',
                       "cve":'//div[@class="container d-flex justify-content-between vul"]//tr//td[2]//text()',
                       "platform":'//div[@class="container d-flex justify-content-between vul"]//tr//td[3]//text()',
                       "pubtime":'//div[@class="container d-flex justify-content-between vul"]//tr//td[4]//text()',
                       "uptime":'//div[@class="container d-flex justify-content-between vul"]//tr//td[5]//text()'
                       })
    lcve = len(vulns["vname"])

    for xxx in range(lcve):
        cc.writelist([
                      vulns["vname"][la(xxx,vulns["vname"])].strip(),
                      baseurl+vulns['vlink'][la(xxx,vulns["vlink"])].strip(),
                      vulns['cve'][la(xxx,vulns["cve"])].strip(),
                      vulns['platform'][la(xxx,vulns["platform"])].strip(),
                      vulns['pubtime'][la(xxx,vulns["pubtime"])].strip(),
                      vulns['uptime'][la(xxx,vulns["uptime"])].strip()
                      ])


# print([x['groupId'][0],x['artifactId'][0],va]+[c for c in [x for x in vulns.values()][0]])
#     # print(x["groupId"][0])
#   https://nvd.nist.gov/vuln/detail/
#   https://www.anquanke.com/vul?page=1


